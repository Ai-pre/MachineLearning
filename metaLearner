# ======================================================
# âš¡ CF(SVD) + CB(Content-Based) Hybrid Meta-Train Builder (Fast Version)
# ======================================================

import pandas as pd
import numpy as np
from surprise import Dataset, Reader, SVD
from sklearn.preprocessing import StandardScaler
from sklearn.metrics.pairwise import cosine_similarity
from tqdm import tqdm
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
import xgboost as xgb

# ------------------------------------------------------
# 1ï¸âƒ£ ë°ì´í„° ë¡œë“œ
# ------------------------------------------------------
meta = pd.read_csv("meta_preprocessed.csv")
ratings_train = pd.read_csv("rating_complete.csv")
ratings_test = pd.read_csv("rating_test.csv")

meta = meta.fillna(0.0)
ratings_train = ratings_train[ratings_train['rating'] > 0]
ratings_test = ratings_test[ratings_test['rating'] > 0]

print(f"âœ… Train: {ratings_train.shape}, Test: {ratings_test.shape}\n")

# ------------------------------------------------------
# 2ï¸âƒ£ CF ëª¨ë¸ (SVD)
# ------------------------------------------------------
reader = Reader(rating_scale=(ratings_train['rating'].min(), ratings_train['rating'].max()))
data = Dataset.load_from_df(ratings_train[['user_id', 'anime_id', 'rating']], reader)
trainset = data.build_full_trainset()

svd = SVD(
    n_factors=100,
    n_epochs=20,
    lr_all=0.005,
    reg_all=0.02,
    random_state=42,
    verbose=True
)
svd.fit(trainset)
print("ğŸ¯ CF (SVD) í•™ìŠµ ì™„ë£Œ!\n")

# ------------------------------------------------------
# 3ï¸âƒ£ ì½˜í…ì¸  í”¼ì²˜ ìŠ¤ì¼€ì¼ë§ ë° ìœ ì‚¬ë„ í–‰ë ¬ ê³„ì‚°
# ------------------------------------------------------
feature_cols = [c for c in meta.columns if c != 'MAL_ID']
scaler = StandardScaler()
X = scaler.fit_transform(meta[feature_cols].values)

malid_to_idx = {aid: i for i, aid in enumerate(meta['MAL_ID'].values)}
idx_to_malid = {v: k for k, v in malid_to_idx.items()}

print("ğŸ§® ì „ì²´ ì•„ì´í…œ ìœ ì‚¬ë„ í–‰ë ¬ ê³„ì‚° ì¤‘...")
item_sim_matrix = cosine_similarity(X)
print("âœ… ìœ ì‚¬ë„ í–‰ë ¬ ê³„ì‚° ì™„ë£Œ!\n")

# ------------------------------------------------------
# 4ï¸âƒ£ CF ì ìˆ˜ í•¨ìˆ˜
# ------------------------------------------------------
def cf_score(user_id, anime_id):
    try:
        return svd.predict(user_id, anime_id).est
    except:
        return np.nan

# ------------------------------------------------------
# 5ï¸âƒ£ CB ì ìˆ˜ ë²¡í„°í™” ë²„ì „ (ìœ ì € ë‹¨ìœ„ ìºì‹±)
# ------------------------------------------------------
def get_cb_scores_for_user(user_id, like_th=8.0):
    """ìœ ì €ê°€ ì¢‹ì•„í•œ ì•„ì´í…œë“¤ì˜ í‰ê·  ìœ ì‚¬ë„ ë²¡í„°ë¥¼ ë¯¸ë¦¬ ê³„ì‚°í•´ë‘”ë‹¤"""
    user_train = ratings_train[ratings_train['user_id'] == user_id]
    liked = user_train[user_train['rating'] >= like_th]['anime_id'].values
    liked_idx = [malid_to_idx[a] for a in liked if a in malid_to_idx]
    if not liked_idx:
        return None  # ì„ í˜¸ ì•„ì´í…œ ì—†ìŒ
    # ì¢‹ì•„í•œ ì• ë‹ˆë“¤ì˜ ìœ ì‚¬ë„ í‰ê·  (ì•„ì´í…œ ì „ì²´ì— ëŒ€í•´)
    return item_sim_matrix[liked_idx].mean(axis=0)

# ------------------------------------------------------
# 6ï¸âƒ£ ë©”íƒ€íŠ¸ë ˆì¸ ìƒì„± (1000ëª… ìƒ˜í”Œë§)
# ------------------------------------------------------
np.random.seed(42)
all_users = ratings_train['user_id'].unique()
sample_users = np.random.choice(all_users, size=min(1000, len(all_users)), replace=False)

meta_train_records = []

print(f"ğŸ‘¥ ì´ {len(all_users)}ëª… ì¤‘ {len(sample_users)}ëª… ìœ ì € ìƒ˜í”Œë§í•˜ì—¬ CB ê³„ì‚°\n")

for uid in tqdm(sample_users, desc="Building Fast Meta-Train"):
    user_data = ratings_train[ratings_train['user_id'] == uid]
    cb_vector = get_cb_scores_for_user(uid)
    if cb_vector is None:
        continue
    for row in user_data.itertuples(index=False):
        aid = row.anime_id
        if aid not in malid_to_idx:
            continue
        cb = cb_vector[malid_to_idx[aid]]  # ìºì‹œëœ ìœ ì‚¬ë„ì—ì„œ ë°”ë¡œ êº¼ëƒ„|
        cf = cf_score(uid, aid)
        meta_train_records.append((uid, aid, cf, cb, row.rating))

meta_train_df = pd.DataFrame(meta_train_records, columns=["user_id", "anime_id", "cf_score", "cb_score", "true_rating"])

# ------------------------------------------------------
# 7ï¸âƒ£ ê²°ê³¼ ì €ì¥
# ------------------------------------------------------
meta_train_df.to_csv("meta_train_ready.csv", index=False)
print("\nğŸ’¾ meta_train_ready.csv ì €ì¥ ì™„ë£Œ!")
print(meta_train_df.head())

# âœ… ìµœì¢… ì¶œë ¥ ì˜ˆì‹œ
print(f"\nğŸ“Š Meta-Train êµ¬ì„± ì™„ë£Œ: {meta_train_df.shape[0]} samples")
print(meta_train_df.describe())


# ======================================================
# ëª¨ë¸ë¡œ ì¶”ì²œ
# ======================================================


# ------------------------------------------------------
# 1ï¸âƒ£ ë°ì´í„° ë¡œë“œ
# ------------------------------------------------------
meta_df = pd.read_csv("meta_train_ready.csv")
anime_info = pd.read_csv("anime.csv")  # ì• ë‹ˆ ì´ë¦„ ë§¤ì¹­ìš©

print(f"âœ… Meta-Train Data: {meta_df.shape}")
print(f"âœ… Anime Info Data: {anime_info.shape}\n")

# ------------------------------------------------------
# 2ï¸âƒ£ ì…ë ¥ / íƒ€ê¹ƒ ë¶„ë¦¬
# ------------------------------------------------------
X = meta_df[["cf_score", "cb_score"]]
y = meta_df["true_rating"]

X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)
print(f"Train: {X_train.shape}, Validation: {X_val.shape}\n")

# ------------------------------------------------------
# 3ï¸âƒ£ ë©”íƒ€ëŸ¬ë„ˆ (XGBoost)
# ------------------------------------------------------
xgb_model = xgb.XGBRegressor(
    n_estimators=300,
    learning_rate=0.05,
    max_depth=6,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42,
    tree_method="hist",
    objective="reg:squarederror"
)

print("ğŸ¯ Training Meta-Learner (XGBoost)...")
xgb_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)
print("âœ… Meta-Learner Training Complete!\n")

# ------------------------------------------------------
# 4ï¸âƒ£ RMSE í‰ê°€
# ------------------------------------------------------
val_pred = xgb_model.predict(X_val)
rmse = np.sqrt(mean_squared_error(y_val, val_pred))
print(f"ğŸ“‰ Validation RMSE: {rmse:.4f}\n")

# ------------------------------------------------------
# 5ï¸âƒ£ ìœ ì €ë³„ ì¶”ì²œ Top-10 (ì´ë¦„ í¬í•¨)
# ------------------------------------------------------
sample_user = meta_df["user_id"].sample(1, random_state=42).iloc[0]
user_data = meta_df[meta_df["user_id"] == sample_user].copy()

# ì˜ˆì¸¡ í‰ì  ê³„ì‚°
user_data["meta_pred"] = xgb_model.predict(user_data[["cf_score", "cb_score"]])

# ì• ë‹ˆ ì´ë¦„ ë³‘í•©
user_data = user_data.merge(anime_info[["MAL_ID", "Name"]], left_on="anime_id", right_on="MAL_ID", how="left")

# ìƒìœ„ 10ê°œ ì¶”ì²œ
top10 = user_data.sort_values("meta_pred", ascending=False).head(10)

print(f"ğŸ¯ User {sample_user}ì˜ ì¶”ì²œ Top-10 ì• ë‹ˆ:")
for _, row in top10.iterrows():
    print(f" - {row['Name']:<40} | ì˜ˆì¸¡í‰ì : {row['meta_pred']:.2f} | ì‹¤ì œ: {row['true_rating']:.1f}")

# ------------------------------------------------------
# 6ï¸âƒ£ ëª¨ë¸ ì €ì¥ (ì„ íƒ)
# ------------------------------------------------------
xgb_model.save_model("meta_learner_xgb.json")
print("\nğŸ’¾ Meta-Learner ëª¨ë¸ ì €ì¥ ì™„ë£Œ!")
